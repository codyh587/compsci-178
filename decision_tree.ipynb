{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362d7d98",
   "metadata": {},
   "source": [
    "### <b>IMDB Decision Tree Classifier</b> by [codyh587](https://github.com/codyh587)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52805cdd",
   "metadata": {},
   "source": [
    "#### Data Setup and Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ebc36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac825e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for low memory VMs, rerunning this may require restarting the kernel\n",
    "def load_imdb_dataset():\n",
    "    gc.collect()\n",
    "\n",
    "    dataset = load_dataset(\"imdb\").shuffle(seed=seed)\n",
    "    vectorizer = TfidfVectorizer().fit(dataset[\"train\"][\"text\"])\n",
    "\n",
    "    train_texts = vectorizer.transform(dataset[\"train\"][\"text\"])\n",
    "    train_labels = np.array(dataset[\"train\"][\"label\"])\n",
    "\n",
    "    test_texts = vectorizer.transform(dataset[\"test\"][\"text\"])\n",
    "    test_labels = np.array(dataset[\"test\"][\"label\"])\n",
    "\n",
    "    del dataset, vectorizer\n",
    "    gc.collect()\n",
    "\n",
    "    train_texts, valid_texts, train_labels, valid_labels = train_test_split(\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        test_size=0.25,\n",
    "        random_state=seed,\n",
    "        stratify=train_labels\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        valid_texts,\n",
    "        valid_labels,\n",
    "        test_texts,\n",
    "        test_labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5746ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels: 0 = negative review, 1 = positive review\n",
    "train_X, train_y, valid_X, valid_y, test_X, test_y = load_imdb_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train texts shape: (18750, 74849)\n",
      "Train labels shape: (18750,)\n",
      "Validation texts shape: (6250, 74849)\n",
      "Validation labels shape: (6250,)\n",
      "Test texts shape: (25000, 74849)\n",
      "Test labels shape: (25000,)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(f\"Training texts shape: {train_X.shape}\")\n",
    "print(f\"Training labels shape: {train_y.shape}\")\n",
    "print(f\"Valid texts shape: {valid_X.shape}\")\n",
    "print(f\"Valid labels shape: {valid_y.shape}\")\n",
    "print(f\"Testing texts shape: {test_X.shape}\")\n",
    "print(f\"Testing labels shape: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d81268",
   "metadata": {},
   "source": [
    "#### Finding Optimal Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc233b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [i for i in range(1, 30)]\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=seed)\n",
    "    clf.fit(train_X, train_y)\n",
    "\n",
    "    train_pred = clf.predict(train_X)\n",
    "    test_pred = clf.predict(test_X)\n",
    "\n",
    "    train_errors.append(1 - accuracy_score(train_y, train_pred))\n",
    "    test_errors.append(1 - accuracy_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(depths, train_errors, label='Training Error')\n",
    "plt.plot(depths, test_errors, label='Testing Error')\n",
    "plt.title('Decision Tree Error vs. Maximum Tree Depth')\n",
    "plt.xlabel('Maximum Tree Depth')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "otter": {
   "OK_FORMAT": false,
   "assignment_name": "hw4",
   "tests": {
    "q2.1 Gini Score Before Splitting": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.1 Gini Score Before Splitting\"\npoints = 3\n\n",
    "q2.2 Gini Score for X1": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.2 Gini Score for X1\"\npoints = 3\n\n",
    "q2.3 Gini Score for X2": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.3 Gini Score for X2\"\npoints = 3\n\n",
    "q2.4 Gini Score for X3": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q2.4 Gini Score for X3\"\npoints = 3\n\n",
    "q3.1 Class Prob Vector": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3.1 Class Prob Vector\"\npoints = 5\n\n@test_case(points=5, hidden=False)\ndef test_class_prob_vector(DecisionTree, np):\n    dt_31 = DecisionTree(max_depth=3)\n    y_31 = np.array([0, 0, 0, 0, 1])\n    expected_31 = np.array([0.8, 0.2])\n    out_31 = dt_31.class_prob_vector(y_31)\n    assert np.allclose(expected_31, out_31, atol=0.001)\n\n",
    "q3.2 Leaf Condition": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3.2 Leaf Condition\"\npoints = 10\n\n@test_case(points=10, hidden=False)\ndef test_leaf_condition(Node, DecisionTree, np):\n    dt_32a = DecisionTree(max_depth=4)\n    node_32a = Node(depth=3)\n    node_32a.probs = np.array([1, 0])\n    expected_32a = True\n    out_32a = dt_32a.leaf_condition(node_32a)\n    dt_32b = DecisionTree(max_depth=4)\n    node_32b = Node(depth=4)\n    node_32b.probs = np.array([0.5, 0.5])\n    expected_32b = True\n    out_32b = dt_32b.leaf_condition(node_32b)\n    assert np.allclose(expected_32a, out_32a, atol=0.001) and np.allclose(expected_32b, out_32b, atol=0.001)\n\n",
    "q3.3 Gini Score": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3.3 Gini Score\"\npoints = 10\n\n@test_case(points=10, hidden=False)\ndef test_gini_score(DecisionTree, np):\n    dt_33 = DecisionTree(max_depth=3)\n    X_33 = np.array([[1, 1], [2, 8], [4, 9], [6, 7], [7, 4], [8, 11], [3, 3], [5, 5], [9, 5], [10, 8], [11, 6], [12, 10]])\n    y_33 = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n    expected_33 = 1 / 4\n    out_33 = dt_33.gini_score(X_33, y_33, 0, 8)\n    assert np.isclose(expected_33, out_33, atol=0.001)\n\n",
    "q3.4 Find Best Split": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3.4 Find Best Split\"\npoints = 15\n\n@test_case(points=15, hidden=False)\ndef test_find_best_split(DecisionTree, np):\n    dt_34 = DecisionTree(max_depth=3)\n    X_34 = np.array([[1, 1], [2, 8], [4, 9], [6, 7], [7, 4], [8, 11], [3, 3], [5, 5], [9, 5], [10, 8], [11, 6], [12, 10]])\n    y_34 = np.array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n    X_L_34, y_L_34 = (X_34[X_34[:, 0] <= 8.5], y_34[X_34[:, 0] <= 8.5])\n    expected_34 = (1, 6)\n    out_34 = dt_34.find_best_split(X_L_34, y_L_34)\n    assert np.allclose(expected_34, out_34, atol=0.001)\n\n",
    "q3.5 Build Tree": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q3.5 Build Tree\"\npoints = 10\n\n@test_case(points=10, hidden=False)\ndef test_build_tree(DecisionTree, np, seed, make_classification, DecisionTreeClassifier):\n    X_34, y_34 = make_classification(n_samples=250, n_features=5, n_informative=3, random_state=seed)\n    sklearn_dt_34 = DecisionTreeClassifier(max_depth=3, criterion='gini', random_state=seed)\n    sklearn_dt_34.fit(X_34, y_34)\n    expected_34 = sklearn_dt_34.predict(X_34)\n    dt_34 = DecisionTree(max_depth=3)\n    dt_34.fit(X_34, y_34)\n    out_34 = dt_34.predict(X_34)\n    assert np.allclose(expected_34, out_34, atol=0.001)\n\n",
    "q4.1b Train and Test Error": "from otter.test_files import test_case\n\nOK_FORMAT = False\n\nname = \"q4.1b Train and Test Error\"\npoints = 1\n\n@test_case(points=1, hidden=False)\ndef test_tree_error(np, clf_err_tr, clf_err_te):\n    assert np.isclose(clf_err_tr, 0.04020100502512558, atol=0.001)\n    assert np.isclose(clf_err_te, 0.07602339181286555, atol=0.001)\n\n"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
